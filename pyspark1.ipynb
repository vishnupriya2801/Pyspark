{"cells":[{"cell_type":"code","source":["from pyspark import SparkConf\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.master(\"local\").config(conf=SparkConf()).getOrCreate()"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["orders_csv = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/orders.csv')\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["customers_csv = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/customers.csv')"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pyspark.sql import functions as f\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["orders_text_split=orders_csv.select(\nf.split(orders_csv.column_name,',')[0].cast('int').alias('order_customer_id'),\nf.split(orders_csv.column_name,',')[1].cast('date').alias('order_date'),\nf.split(orders_csv.column_name,',')[2].cast('int').alias('order_id'),\nf.split(orders_csv.column_name,',')[3].cast('string').alias('order_status')\n)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["orders_text_split.show(5)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["customers_text_split=customers_csv.select(\nf.split(customers_csv.column_name,',')[0].cast('int').alias('customer_id'),\nf.split(customers_csv.column_name,',')[1].cast('string').alias('customer_fname'),\nf.split(customers_csv.column_name,',')[2].cast('string').alias('customer_lname'),\nf.split(customers_csv.column_name,',')[3].cast('string').alias('customer_email'),\nf.split(customers_csv.column_name,',')[4].cast('string').alias('customer_password'),\nf.split(customers_csv.column_name,',')[5].cast('string').alias('customer_street'),\nf.split(customers_csv.column_name,',')[6].cast('string').alias('customer_city'),\nf.split(customers_csv.column_name,',')[7].cast('string').alias('customer_state'),\nf.split(customers_csv.column_name,',')[8].cast('string').alias('customer_zipcode')\n)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["customers_text_split.show(5)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["customers_text_split.join(orders_text_split,customers_text_split.customer_id==orders_text_split.order_customer_id,\"inner\").\\\ngroupBy(customers_text_split.customer_state,orders_text_split.order_status).\\\nagg(f.count(orders_text_split.order_customer_id).alias(\"count\")).\\\nfilter(\"order_status in ('COMPLETE','CLOSED','PROCESSING')\").where(\"count >50\").\\\norderBy([\"customer_state\",\"count\"],ascending=[0,1]).\\\nselect(f.format_string(\"%s,%s,%d\",\"customer_state\",\"order_status\",\"count\").alias('ANSWER')).show()\n"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":10}],"metadata":{"name":"pyspark1","notebookId":3149372371065118},"nbformat":4,"nbformat_minor":0}
